{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KLjrWksedRImg9YmPgstq1TFupWK6B00",
      "authorship_tag": "ABX9TyPgdVfFsrAtDEX4c8A+4FGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonzyyyy/AlphaLab/blob/main/AlphaLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup & Libraries"
      ],
      "metadata": {
        "id": "Kqug1TykAN0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up necessary keys and env variables\n",
        "(only required to run at the start of execution)"
      ],
      "metadata": {
        "id": "9eCOk5WuJ9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv --quiet\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy Alpha Lab notebook to folder\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/AlphaLab.ipynb\" AlphaLab/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_BlMFEsIuLR",
        "outputId": "e54f8467-0a07-4be8-9e79-6b68cdf06535"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cp: cannot create regular file 'AlphaLab/': Not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance --quiet\n",
        "!pip install vectorbt --quiet\n",
        "!pip install streamlit pyngrok --quiet"
      ],
      "metadata": {
        "id": "1JObZn26AJuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0b3500-248b-4f18-fc4f-6d1e4035c51a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/527.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.8/527.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import vectorbt as vbt\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from pyngrok import ngrok\n",
        "import os"
      ],
      "metadata": {
        "id": "FWBO-BI9if36"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code below expects a secret that contains the necessary private API keys.\n",
        "\n",
        "API Keys required:\n",
        "1. NGROK"
      ],
      "metadata": {
        "id": "xCOb4_7sOgeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ngrok config add-authtoken NGROK_API_KEY\n",
        "from google.colab import userdata\n",
        "ngrok_token = userdata.get('NGROK_API_KEY')\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "id": "U498HRGpNJmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee6a6a1-63c7-4402-de7f-654180ca31bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "SPLIT_RATIO = 0.7\n",
        "DATA_YEARS = 2\n",
        "TOP_N_STOCKS = 5\n",
        "benchmark_ticker = 'SPY' # Benchmark ticker\n",
        "SUBSET_SIZE = 25\n",
        "STARTING_AMOUNT = 10000 # Starting amount of portfolio\n",
        "\n",
        "# --- Caching Configuration for S&P500 Data ---\n",
        "DEBUG = True # Set to True to use cached data, False to fetch live data.\n",
        "CACHE_FILE = 'sp500_market_caps.csv'"
      ],
      "metadata": {
        "id": "LuXrEzShQ9R7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download S&P 500 Stocks List\n",
        "For simplicity, we'll fetch the tickers from Wikipedia"
      ],
      "metadata": {
        "id": "L5pMMEWJAS_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Caching Logic ---\n",
        "if DEBUG and os.path.exists(CACHE_FILE):\n",
        "    print(f\"DEBUG mode is ON. Loading data from cache file: {CACHE_FILE}\")\n",
        "    market_caps_df = pd.read_csv(CACHE_FILE)\n",
        "else:\n",
        "    print(f\"Fetching live data. DEBUG is OFF or cache file not found.\")\n",
        "    # Get S&P 500 tickers from Wikipedia\n",
        "    sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "    sp500_table = pd.read_html(sp500_url)\n",
        "    sp500 = sp500_table[0]\n",
        "    # Correctly handle potential discrepancies in ticker symbols (e.g., 'BRK.B' vs 'BRK-B')\n",
        "    tickers = sp500['Symbol'].str.replace('.', '-', regex=False).tolist()\n",
        "\n",
        "    # We'll store market caps in a list of tuples\n",
        "    market_caps = []\n",
        "\n",
        "    print(\"Downloading market cap data for S&P 500 tickers...\")\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            info = yf.Ticker(ticker).info\n",
        "            cap = info.get('marketCap', None)\n",
        "            if cap is not None:\n",
        "                market_caps.append((ticker, cap))\n",
        "        except Exception as e:\n",
        "            # print(f\"Could not fetch data for {ticker}: {e}\")\n",
        "            continue  # skip tickers with issues\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    market_caps_df = pd.DataFrame(market_caps, columns=['Ticker', 'MarketCap'])\n",
        "\n",
        "    # Sort by market cap, descending\n",
        "    market_caps_df = market_caps_df.sort_values(by='MarketCap', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Save the fetched data to the cache file for future use\n",
        "    market_caps_df.to_csv(CACHE_FILE, index=False)\n",
        "    print(f\"Live data saved to cache file: {CACHE_FILE}\")\n",
        "\n",
        "# --- Display the result ---\n",
        "print(\"\\nTop 5 S&P 500 companies by market cap:\")\n",
        "print(market_caps_df.head())"
      ],
      "metadata": {
        "id": "x_-k1-C-ASXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7938e80-7d19-4144-eea4-921c5c757dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching live data. DEBUG is OFF or cache file not found.\n",
            "Downloading market cap data for S&P 500 tickers...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(market_caps_df.head(5))  # Show top 5 largest S&P 500 stocks\n",
        "# (Optional) Use a smaller subset for a fast demo\n",
        "# tickers = market_caps_df['Ticker'][:SUBSET_SIZE].tolist()\n",
        "# print(tickers)"
      ],
      "metadata": {
        "id": "TQ7Va2ZVFQau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 3. Download Price Data\n",
        "# =======================\n",
        "end = datetime.today()\n",
        "start = end - timedelta(days=365*DATA_YEARS)  # Last 2 years\n",
        "price_data = yf.download(tickers, start=start, end=end, group_by='ticker', auto_adjust=True, progress=False)\n",
        "# print(price_data.head(3))"
      ],
      "metadata": {
        "id": "9PvUfBfzAelB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 4. Train-Test Split\n",
        "# =======================\n",
        "all_dates = price_data[tickers[0]]['Close'].index\n",
        "split_idx = int(len(all_dates) * SPLIT_RATIO)\n",
        "train_dates = all_dates[:split_idx]\n",
        "test_dates = all_dates[split_idx:]\n",
        "print(len(all_dates), len(test_dates))\n",
        "\n",
        "# Helper function to get price for a given ticker and period\n",
        "def get_close_prices(ticker, dates):\n",
        "    try:\n",
        "        close = price_data[ticker]['Close'].reindex(dates)\n",
        "        return close\n",
        "    except:\n",
        "        return pd.Series(index=dates, dtype=float)"
      ],
      "metadata": {
        "id": "Z9jjdz7wPlwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Factor Based Algorithmic Equity Strategy\n",
        "\n",
        "## Factor Used\n",
        "1. Trailing P/E ratio - measures a company's current share price against its actual, historical earnings from the previous 12 months\n",
        "\n",
        "    **Formula**: `Current Share Price / Trailing 12-Month EPS`\n",
        "\n",
        "    **Limitation**: Past performance is not a guarantee of future results\n",
        "\n",
        "2. The 6-Month Price Momentum factor is a strategy that aims to capitalize on existing market trends by identifying stocks that have performed well in the recent past\n",
        "\n",
        "    **Formula**: `(Current Price / Price from 6 Months Ago) - 1`\n",
        "\n",
        "    **Limitation**: A key risk is a momentum crash or reversal\n",
        "\n",
        "## To consider\n",
        "1. Forward P/E ratio - forward-looking metric that measures a company's current share price relative to its estimated future earnings per share (EPS)\n",
        "\n",
        "    **Formula**: `Current Share Price / Forecasted 12-Month EPS`\n",
        "\n",
        "    **Limitation**: Its primary weakness is that it's based on estimates, which can be inaccurate, overly optimistic, or change frequently.\n",
        "\n"
      ],
      "metadata": {
        "id": "2wZPtTw8a-o6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "132c4543"
      },
      "source": [
        "class Factor:\n",
        "    \"\"\"Base class for financial factors.\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def calculate(self, price_data_close, tickers):\n",
        "        \"\"\"\n",
        "        Calculates the factor for the given tickers using point-in-time price data.\n",
        "        Must be implemented by subclasses.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclass must implement abstract method\")\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_factors(price_data_close, subset_tickers, factors):\n",
        "        \"\"\"\n",
        "        Calculates specified factors for a subset of tickers using point-in-time data.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices with tickers as columns.\n",
        "            subset_tickers (list): List of tickers to calculate factors for.\n",
        "            factors (list): List of Factor objects to calculate.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with factors as columns and tickers as index.\n",
        "        \"\"\"\n",
        "        factor_data = {}\n",
        "        valid_tickers_with_data = [\n",
        "            ticker for ticker in subset_tickers if ticker in price_data_close.columns and not price_data_close[ticker].dropna().empty\n",
        "        ]\n",
        "        print(f\"Calculating factors for {len(valid_tickers_with_data)} valid tickers...\")\n",
        "\n",
        "        for factor in factors:\n",
        "            factor_values = []\n",
        "            # print(f\"  Calculating {factor.name}...\")\n",
        "            for ticker in valid_tickers_with_data:\n",
        "                try:\n",
        "                    # Pass relevant data to the factor's calculate method\n",
        "                    value = factor.calculate(price_data_close[[ticker]].copy(), [ticker]) # Pass single ticker DataFrame\n",
        "                    factor_values.append(value)\n",
        "                except Exception as e:\n",
        "                    # print(f\"    Error calculating {factor.name} for {ticker}: {e}\")\n",
        "                    factor_values.append(np.nan) # Append NaN if calculation fails\n",
        "\n",
        "            factor_data[factor.name] = factor_values\n",
        "\n",
        "        factor_df = pd.DataFrame(factor_data, index=valid_tickers_with_data)\n",
        "        factor_df = factor_df.dropna() # Drop tickers with NaN in any factor\n",
        "\n",
        "        # print(f\"Factor DataFrame after calculation and dropna:\\n{factor_df.head()}\")\n",
        "\n",
        "        return factor_df\n",
        "\n",
        "\n",
        "class Value(Factor):\n",
        "    \"\"\"Value factor based on Trailing P/E ratio.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__('pe_ratio')\n",
        "\n",
        "    def calculate(self, price_data_close, tickers):\n",
        "        \"\"\"\n",
        "        Calculates the Trailing P/E ratio for a given ticker.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices for a single ticker.\n",
        "            tickers (list): A list containing the single ticker symbol.\n",
        "\n",
        "        Returns:\n",
        "            float: The Trailing P/E ratio or np.nan if unavailable.\n",
        "        \"\"\"\n",
        "        if not tickers or not isinstance(tickers, list) or len(tickers) != 1:\n",
        "            # print(\"Value factor requires a single ticker.\")\n",
        "            return np.nan\n",
        "        ticker = tickers[0]\n",
        "        try:\n",
        "            info = yf.Ticker(ticker).info\n",
        "            pe_ratio = info.get('trailingPE', np.nan)\n",
        "            # print(f\"  PE for {ticker}: {pe_ratio}\")\n",
        "            return pe_ratio\n",
        "        except Exception as e:\n",
        "            # print(f\"  Error fetching PE for {ticker}: {e}\")\n",
        "            return np.nan\n",
        "\n",
        "\n",
        "class Momentum(Factor):\n",
        "    \"\"\"Momentum factor based on 6-month price return.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__('6m_return')\n",
        "\n",
        "    def calculate(self, price_data_close, tickers):\n",
        "        \"\"\"\n",
        "        Calculates the 6-month price return for a given ticker.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices for a single ticker.\n",
        "            tickers (list): A list containing the single ticker symbol.\n",
        "\n",
        "        Returns:\n",
        "            float: The 6-month return or np.nan if insufficient data.\n",
        "        \"\"\"\n",
        "        if not tickers or not isinstance(tickers, list) or len(tickers) != 1:\n",
        "            # print(\"Momentum factor requires a single ticker.\")\n",
        "            return np.nan\n",
        "        ticker = tickers[0]\n",
        "        try:\n",
        "            # Ensure the price_data_close for the single ticker is a Series\n",
        "            prices = price_data_close[ticker].dropna()\n",
        "            # print(f\"  Prices length for {ticker}: {len(prices)}\") #\n",
        "            if len(prices) > 126: # Approximately 6 months of trading days\n",
        "                return_6m = (prices.iloc[-1] / prices.iloc[-126]) - 1\n",
        "                # print(f\"  6m return for {ticker}: {return_6m}\") #\n",
        "                return return_6m\n",
        "            else:\n",
        "                return np.nan\n",
        "        except Exception as e:\n",
        "            # print(f\"  Error calculating 6m return for {ticker}: {e}\") #\n",
        "            return np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating Initial Factors\n",
        "\n",
        "The static method `calculate_factors` from the `Factor` class is used to perform the initial factor calculations. The following parameters are passed to the method:\n",
        "* The relevant price data, specifically the `price_data_close` DataFrame.\n",
        "* The list of tickers being considered, stored in `subset_tickers`.\n",
        "* A list of the factor objects that need to be calculated.\n",
        "\n",
        "**Note on Point-in-Time Data:** This initial calculation uses all available price data. This is not strictly point-in-time accurate as it includes future data relative to the start of the backtest. However, this is done for an initial assessment, and the main backtesting loop later recalculates these factors correctly using only the data available at each specific rebalance point. This step assumes the `price_data_close` and `subset_tickers` variables have been defined previously."
      ],
      "metadata": {
        "id": "2ymYXWEeuPa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 5. Factor Calculation (Value, Momentum) - Refactored\n",
        "# =======================\n",
        "\n",
        "# Filter subset_tickers based on available data in price_data\n",
        "available_tickers = [ticker for ticker in tickers if ticker in price_data.columns.get_level_values(0)]\n",
        "missing_tickers = [ticker for ticker in tickers if ticker not in price_data.columns.get_level_values(0)]\n",
        "\n",
        "if missing_tickers:\n",
        "    print(f\"Warning: Data not available for the following tickers in price_data: {missing_tickers}. Skipping these for factor calculation.\")\n",
        "\n",
        "subset_tickers_filtered = available_tickers\n",
        "print(f\"Filtered subset_tickers: {subset_tickers_filtered}\")\n",
        "\n",
        "\n",
        "# Instantiate the factor classes\n",
        "value_factor = Value()\n",
        "momentum_factor = Momentum()\n",
        "\n",
        "# Create a list of factors to use\n",
        "factors_to_calculate = [value_factor, momentum_factor]\n",
        "\n",
        "# Need to make sure price_data_close is aligned with subset_tickers and only contains Close prices\n",
        "# We can reuse the logic from the backtesting cell for preparing price_data_close\n",
        "# Note: This part still assumes 'price_data' is available and has the MultiIndex structure from yf.download\n",
        "if isinstance(price_data.columns, pd.MultiIndex):\n",
        "     # Select 'Close' for all tickers in subset_tickers_filtered\n",
        "     price_data_close_all = price_data.loc[:, (subset_tickers_filtered, 'Close')]\n",
        "     # Drop the 'Price' level to have tickers as single-level columns\n",
        "     price_data_close_all.columns = price_data_close_all.columns.droplevel('Price')\n",
        "\n",
        "else: # Handle case where price_data might not have a MultiIndex (e.g., single ticker download)\n",
        "     # Assuming it's already the close series for a single ticker, convert to DataFrame\n",
        "     price_data_close_all = pd.DataFrame(price_data)\n",
        "     # Assuming subset_tickers_filtered has only one ticker in this case\n",
        "     # This case might need adjustment if subset_tickers_filtered has multiple items but price_data is not MultiIndex\n",
        "     if len(subset_tickers_filtered) == 1:\n",
        "         price_data_close_all.columns = [subset_tickers_filtered[0]]\n",
        "     else:\n",
        "         print(\"Warning: price_data is not MultiIndex but subset_tickers_filtered has multiple items.\")\n",
        "         price_data_close_all = price_data[subset_tickers_filtered]\n",
        "\n",
        "\n",
        "# Now use the refactored calculate_factors method\n",
        "factor_df = Factor.calculate_factors(price_data_close_all, subset_tickers_filtered, factors_to_calculate)"
      ],
      "metadata": {
        "id": "0HJP3ECEAhNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b4adc29"
      },
      "source": [
        "class StockSelector:\n",
        "    \"\"\"Handles composite scoring and stock selection based on factor data.\"\"\"\n",
        "\n",
        "    def __init__(self, factor_df, num_stocks_to_select):\n",
        "        \"\"\"\n",
        "        Initializes the StockSelector.\n",
        "\n",
        "        Args:\n",
        "            factor_df (pd.DataFrame): DataFrame with factors as columns and tickers as index.\n",
        "            num_stocks_to_select (int): The number of top stocks to select.\n",
        "        \"\"\"\n",
        "        self.factor_df = factor_df.copy() # Work on a copy to avoid modifying the original\n",
        "        self.num_stocks_to_select = num_stocks_to_select\n",
        "        self.selected_tickers = []\n",
        "\n",
        "    def perform_selection(self):\n",
        "        \"\"\"\n",
        "        Performs composite scoring and selects the top N stocks.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of selected ticker symbols.\n",
        "        \"\"\"\n",
        "        if self.factor_df.empty:\n",
        "            print(\"Factor DataFrame is empty. Cannot perform selection.\")\n",
        "            return []\n",
        "\n",
        "        # Ensure 'pe_ratio' and '6m_return' columns exist before ranking\n",
        "        if 'pe_ratio' in self.factor_df.columns and '6m_return' in self.factor_df.columns:\n",
        "            # Rank: lower P/E is better, higher momentum is better\n",
        "            # Handle NaNs in ranking by pushing them to the bottom (worst rank)\n",
        "            self.factor_df['pe_rank'] = self.factor_df['pe_ratio'].rank(ascending=True, na_option='bottom')\n",
        "            self.factor_df['mom_rank'] = self.factor_df['6m_return'].rank(ascending=False, na_option='bottom')\n",
        "\n",
        "            # Simple equal-weight composite score\n",
        "            # Fill NaNs in ranks with a value larger than any possible rank to ensure they get the worst composite score\n",
        "            max_rank = self.factor_df.shape[0]\n",
        "            self.factor_df['composite_score'] = (self.factor_df['pe_rank'].fillna(max_rank + 1) + self.factor_df['mom_rank'].fillna(max_rank + 1)) / 2\n",
        "\n",
        "            # Select top N stocks\n",
        "            # Ensure there are enough stocks to select num_stocks_to_select\n",
        "            if not self.factor_df.empty and self.factor_df.shape[0] >= self.num_stocks_to_select:\n",
        "                 selected = self.factor_df.nsmallest(self.num_stocks_to_select, 'composite_score')\n",
        "                 self.selected_tickers = selected.index.tolist()\n",
        "                 print(f\"Selected top {self.num_stocks_to_select} stocks: {self.selected_tickers}\")\n",
        "            elif not self.factor_df.empty:\n",
        "                 # If fewer than num_stocks_to_select are available, select all available\n",
        "                 self.selected_tickers = self.factor_df.nsmallest(self.factor_df.shape[0], 'composite_score').index.tolist()\n",
        "                 print(f\"Selected {len(self.selected_tickers)} stocks (fewer than requested {self.num_stocks_to_select}): {self.selected_tickers}\")\n",
        "            else:\n",
        "                print(\"No stocks available for selection after scoring.\")\n",
        "                self.selected_tickers = []\n",
        "        else:\n",
        "            print(\"Required factor columns ('pe_ratio', '6m_return') not found in factor_df for scoring.\")\n",
        "            self.selected_tickers = []\n",
        "\n",
        "        return self.selected_tickers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ff8a959"
      },
      "source": [
        "# =======================\n",
        "# 6. Composite Scoring & Stock Selection\n",
        "# =======================\n",
        "\n",
        "# Instantiate the StockSelector class\n",
        "stock_selector = StockSelector(factor_df, TOP_N_STOCKS)\n",
        "\n",
        "# Use the perform_selection method to get the selected tickers\n",
        "selected_tickers = stock_selector.perform_selection()\n",
        "\n",
        "# Print the initial selected tickers\n",
        "print(\"\\nInitial selected stocks based on all data:\", selected_tickers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rebalancing and Backtesting strategy\n",
        "Based on your code, here is a high-level explanation of how the rebalancing and backtesting strategy works. This process is designed to realistically simulate how an active investment strategy would be managed over time.\n",
        "\n",
        "### **High-Level Strategy Explanation**\n",
        "\n",
        "The strategy operates like a dynamic fund manager who periodically re-evaluates the market and adjusts their portfolio. It does this by looping through time in quarterly intervals and making investment decisions based **only on the information available at each point in time**.\n",
        "\n",
        "Here is the step-by-step process:\n",
        "\n",
        "1.  **Preparation**: The backtest first defines a \"test period\" (e.g., the last 30% of your historical data) and identifies the start date of each quarter within that period. These dates become the scheduled \"rebalancing days.\"\n",
        "\n",
        "2.  **The Simulation Loop**: The code then simulates the passing of time by looping through each rebalancing day. At each of these dates, it performs the following actions:\n",
        "    * **Point-in-Time Analysis**: It looks backward, using only the historical data available up to that specific day to re-calculate the Value and Momentum factors for all stocks.\n",
        "    * **Portfolio Re-Selection**: Based on these fresh, point-in-time factor scores, it re-ranks the stocks and selects the new \"Top N\" stocks to form the portfolio for the upcoming quarter.\n",
        "    * **Holding Period**: The strategy then \"holds\" this newly selected portfolio until the next rebalancing day, recording its daily performance during this period.\n",
        "\n",
        "3.  **Performance Calculation**: After the loop has run through all the quarters, the daily returns from each individual holding period are \"stitched\" together into one continuous performance history for the entire strategy.\n",
        "\n",
        "4.  **Final Analysis**: This complete and stitched-together series of returns is used to calculate the final cumulative return and overall performance metrics like Annualized Return, Volatility, and the Sharpe Ratio.\n",
        "\n",
        "This point-in-time rebalancing approach is a robust method because it avoids **lookahead bias**, ensuring that investment decisions are never made using information that would not have been available at the time.\n",
        "\n",
        "## Future implementations\n",
        "\n",
        "Metrics\n",
        "1. Add Maximum Drawdown\n",
        "2. Add Volatility\n",
        "3. Alpha\n",
        "4. Calmar Ratio (`Annualized Return / Max Drawdown`)\n",
        "5. Max drawdown\n",
        "6. Portfolio Turnover\n",
        "\n",
        "Additional points\n",
        "1. Accounting for transaction fees, slippage\n",
        "2. Address survivorship bias"
      ],
      "metadata": {
        "id": "OGtpduH75Rb5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ef9fe4"
      },
      "source": [
        "class Backtester:\n",
        "    \"\"\"\n",
        "    Encapsulates the backtesting logic for a factor-based strategy.\n",
        "    \"\"\"\n",
        "    def __init__(self, price_data_close, subset_tickers, split_ratio, top_n_stocks, rebalance_freq='QS'):\n",
        "        \"\"\"\n",
        "        Initializes the Backtester.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices with tickers as columns.\n",
        "            subset_tickers (list): List of tickers to consider for selection.\n",
        "            split_ratio (float): Ratio of data to use for training (defines the start of the test period).\n",
        "            top_n_stocks (int): The number of top stocks to select at each rebalance.\n",
        "            rebalance_freq (str): Frequency string for rebalancing (e.g., 'QS' for quarterly).\n",
        "        \"\"\"\n",
        "        self.price_data_close = price_data_close.copy()\n",
        "        self.subset_tickers = subset_tickers\n",
        "        self.split_ratio = split_ratio\n",
        "        self.top_n_stocks = top_n_stocks\n",
        "        self.rebalance_freq = rebalance_freq\n",
        "        self.starting_amount = 1 # default starting portfolio value is $1\n",
        "        self.rebalance_dates = None\n",
        "        self.selected_tickers = None\n",
        "\n",
        "        # Initialize attributes to store results\n",
        "        self.portfolio_returns = None\n",
        "        self.cum_returns = None\n",
        "        self.total_return = None\n",
        "        self.annualized_return = None\n",
        "        self.annualized_vol = None\n",
        "        self.sharpe_ratio = None\n",
        "\n",
        "    def _get_test_period_dates(self):\n",
        "        \"\"\"\n",
        "        Identifies and returns the test period dates based on the split ratio.\n",
        "\n",
        "        Returns:\n",
        "            pd.DatetimeIndex: A DatetimeIndex containing the dates for the test period.\n",
        "        \"\"\"\n",
        "        all_dates = self.price_data_close.index\n",
        "        split_idx = int(len(all_dates) * self.split_ratio)\n",
        "        test_dates = all_dates[split_idx:]\n",
        "        return test_dates\n",
        "\n",
        "\n",
        "    def _calculate_rebalance_dates(self, test_dates):\n",
        "        \"\"\"\n",
        "        Calculates the dates on which to rebalance the portfolio.\n",
        "\n",
        "        Args:\n",
        "            test_dates (pd.DatetimeIndex): The dates for the test period.\n",
        "\n",
        "        Returns:\n",
        "            pd.DatetimeIndex: A DatetimeIndex containing the rebalance dates.\n",
        "        \"\"\"\n",
        "        if test_dates.empty:\n",
        "             print(\"Warning: Test period is empty. Adjust split ratio or data years.\")\n",
        "             return pd.DatetimeIndex([]) # Return an empty DatetimeIndex\n",
        "\n",
        "\n",
        "        test_start_date, test_end_date = test_dates[0], test_dates[-1]\n",
        "        rebalance_dates = pd.date_range(start=test_start_date, end=test_end_date, freq=self.rebalance_freq)\n",
        "\n",
        "        # Ensure the first day of the test period is included if it's not a quarter start\n",
        "        if test_start_date not in rebalance_dates:\n",
        "            rebalance_dates = rebalance_dates.insert(0, test_start_date)\n",
        "        return rebalance_dates\n",
        "\n",
        "\n",
        "    def _perform_point_in_time_analysis(self, current_date):\n",
        "        \"\"\"\n",
        "        Extracts point-in-time data, calculates factors, and selects top stocks for a given date.\n",
        "\n",
        "        Args:\n",
        "            current_date (pd.Timestamp): The date for which to perform the analysis.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of selected ticker symbols for the current period, or an empty list if selection fails.\n",
        "        \"\"\"\n",
        "        print(f\"\\nRebalancing for period starting {current_date.date()}...\")\n",
        "        point_in_time_data = self.price_data_close[self.price_data_close.index <= current_date]\n",
        "\n",
        "        if point_in_time_data.empty:\n",
        "            print(\"  -> Skipping: Not enough historical data to calculate factors.\")\n",
        "            return []\n",
        "\n",
        "        print(f\"Analysing point in time data from {point_in_time_data.index[0].date()} to {point_in_time_data.index[-1].date()}\")\n",
        "\n",
        "        # Recalculate factors using only point-in-time data\n",
        "        value_factor = Value() # Assuming Value and Momentum classes are available\n",
        "        momentum_factor = Momentum()\n",
        "        factors_to_calculate = [Value(), Momentum()]\n",
        "\n",
        "        # Use the calculate_factors static method from the Factor class\n",
        "        factor_df_point_in_time = Factor.calculate_factors(point_in_time_data, self.subset_tickers, factors_to_calculate)\n",
        "\n",
        "\n",
        "        if factor_df_point_in_time.empty:\n",
        "            print(\"  -> Skipping: No valid tickers after factor calculation.\")\n",
        "            return []\n",
        "\n",
        "        # Perform Composite Scoring and Select Top N stocks based on the point-in-time factor_df\n",
        "        stock_selector_point_in_time = StockSelector(factor_df_point_in_time, self.top_n_stocks)\n",
        "        current_period_selected_tickers = stock_selector_point_in_time.perform_selection()\n",
        "\n",
        "        if not current_period_selected_tickers:\n",
        "             print(f\"  -> No stocks selected for period starting {current_date.date()}.\")\n",
        "             return [] # No stocks selected for this period\n",
        "        else:\n",
        "            print(f\"  -> New portfolio selected for period starting {current_date.date()}: {current_period_selected_tickers}\")\n",
        "            return current_period_selected_tickers\n",
        "\n",
        "\n",
        "    def _calculate_holding_period_returns(self, start_date, end_date, selected_tickers):\n",
        "        \"\"\"\n",
        "        Calculates the returns for a given holding period and selected tickers.\n",
        "\n",
        "        Args:\n",
        "            start_date (pd.Timestamp): The start date of the holding period.\n",
        "            end_date (pd.Timestamp): The end date of the holding period.\n",
        "            selected_tickers (list): A list of ticker symbols held during the period.\n",
        "\n",
        "        Returns:\n",
        "            pd.Series: A time series of equal-weighted daily returns for the holding period, or an empty Series if no data.\n",
        "        \"\"\"\n",
        "        if not selected_tickers:\n",
        "            return pd.Series()\n",
        "\n",
        "        holding_period_mask = (self.price_data_close.index >= start_date) & (self.price_data_close.index < end_date)\n",
        "        holding_period_prices = self.price_data_close[holding_period_mask]\n",
        "\n",
        "        if not holding_period_prices.empty and selected_tickers:\n",
        "            valid_tickers_in_holding_period = [t for t in selected_tickers if t in holding_period_prices.columns]\n",
        "            if valid_tickers_in_holding_period:\n",
        "                period_prices_selected = holding_period_prices[valid_tickers_in_holding_period]\n",
        "                period_returns = period_prices_selected.pct_change().fillna(0)\n",
        "                # Assume equal weight for the period\n",
        "                equal_weight_returns = period_returns.mean(axis=1)\n",
        "                return equal_weight_returns\n",
        "            else:\n",
        "                print(f\"  -> No valid selected tickers found in price data for holding period starting {start_date.date()}.\")\n",
        "                return pd.Series(index=holding_period_prices.index) # Return empty series with correct index\n",
        "        else:\n",
        "            print(f\"  -> No data for holding period starting {start_date.date()}.\")\n",
        "            return pd.Series() # Return empty series\n",
        "\n",
        "\n",
        "    def _concatenate_and_process_returns(self, all_period_returns, test_dates):\n",
        "        \"\"\"\n",
        "        Concatenates all period returns, calculates cumulative returns, reindexes, and forward fills.\n",
        "\n",
        "        Args:\n",
        "            all_period_returns (list): A list of pandas Series, each containing returns for a holding period.\n",
        "            test_dates (pd.DatetimeIndex): The full range of test period dates.\n",
        "        \"\"\"\n",
        "        if all_period_returns:\n",
        "            self.portfolio_returns = pd.concat(all_period_returns).sort_index()\n",
        "            self.portfolio_returns = self.portfolio_returns[~self.portfolio_returns.index.duplicated(keep='first')]\n",
        "\n",
        "            # 5. Calculate final cumulative returns\n",
        "            self.cum_returns = (1 + self.portfolio_returns).cumprod()\n",
        "\n",
        "            # Prepend a starting value of 1 at the very beginning of the test period\n",
        "            actual_start_date = self.portfolio_returns.index[0] if not self.portfolio_returns.empty else test_dates[0]\n",
        "            start_value_series = pd.Series([1.0], index=[actual_start_date - pd.Timedelta(days=1)])\n",
        "            self.cum_returns = pd.concat([start_value_series, self.cum_returns])\n",
        "\n",
        "            # Reindex to the full test_dates and forward fill\n",
        "            self.cum_returns = self.cum_returns.reindex(test_dates)\n",
        "            self.cum_returns = self.cum_returns.ffill()\n",
        "\n",
        "            print(\"\\n--- Backtest Returns Processed ---\")\n",
        "        else:\n",
        "            print(\"\\nBacktest could not be completed. No returns were generated.\")\n",
        "            self.portfolio_returns = pd.Series(index=test_dates if test_dates else None)\n",
        "            self.cum_returns = pd.Series(index=test_dates if test_dates else None)\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the point-in-time backtesting loop with quarterly rebalancing.\n",
        "        \"\"\"\n",
        "        test_dates = self._get_test_period_dates()\n",
        "        rebalance_dates = self._calculate_rebalance_dates(test_dates)\n",
        "\n",
        "        if rebalance_dates.empty: # Check for empty DatetimeIndex\n",
        "            print(\"No rebalance dates available\")\n",
        "            # Ensure returns are initialized if no rebalance dates\n",
        "            self.portfolio_returns = pd.Series(index=test_dates)\n",
        "            self.cum_returns = pd.Series(index=test_dates)\n",
        "            return\n",
        "\n",
        "        # Loop through rebalance dates to simulate the strategy\n",
        "        all_period_returns = []\n",
        "        last_rebalance_date = None\n",
        "        last_selected_tickers = []\n",
        "\n",
        "        print(f\"Starting point-in-time backtest with {len(rebalance_dates)} rebalance periods...\")\n",
        "\n",
        "        for i, rebalance_date in enumerate(rebalance_dates):\n",
        "            if last_rebalance_date is not None and last_selected_tickers:\n",
        "                # Calculate returns for the previously selected portfolio during the last holding period\n",
        "                holding_period_returns = self._calculate_holding_period_returns(last_rebalance_date, rebalance_date, last_selected_tickers)\n",
        "                if not holding_period_returns.empty:\n",
        "                    all_period_returns.append(holding_period_returns)\n",
        "\n",
        "\n",
        "            # --- Point-in-Time Analysis for the current rebalance_date ---\n",
        "            current_period_selected_tickers = self._perform_point_in_time_analysis(rebalance_date)\n",
        "\n",
        "            last_selected_tickers = current_period_selected_tickers\n",
        "            last_rebalance_date = rebalance_date\n",
        "\n",
        "        # After the loop, process the returns from the last holding period\n",
        "        if last_rebalance_date is not None and last_selected_tickers:\n",
        "            final_holding_period_returns = self._calculate_holding_period_returns(last_rebalance_date, test_dates[-1] + pd.Timedelta(days=1), last_selected_tickers) # Add a day to include the last day\n",
        "            if not final_holding_period_returns.empty:\n",
        "                all_period_returns.append(final_holding_period_returns)\n",
        "\n",
        "        # Concatenate and process all collected returns\n",
        "        self._concatenate_and_process_returns(all_period_returns, test_dates)\n",
        "\n",
        "\n",
        "    def calculate_performance_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculates and stores key performance metrics.\n",
        "        Assumes run_backtest has been called and self.portfolio_returns and self.cum_returns are populated.\n",
        "        \"\"\"\n",
        "        if self.portfolio_returns is None or self.portfolio_returns.empty or len(self.cum_returns) <= 1:\n",
        "            print(\"\\nNot enough data to calculate performance metrics.\")\n",
        "            self.total_return = np.nan\n",
        "            self.annualized_return = np.nan\n",
        "            self.annualized_vol = np.nan\n",
        "            self.sharpe_ratio = np.nan\n",
        "            return\n",
        "\n",
        "        # Ensure metrics are calculated on the non-NaN parts of the cumulative returns series\n",
        "        if not self.cum_returns.dropna().empty and len(self.cum_returns.dropna()) > 1:\n",
        "            self.total_return = self.cum_returns.dropna().iloc[-1] - 1\n",
        "\n",
        "            # Calculate duration based on the actual number of trading days in the portfolio_returns series\n",
        "            duration_trading_days = len(self.portfolio_returns)\n",
        "            annualization_factor = 252 / duration_trading_days if duration_trading_days > 0 else 0\n",
        "\n",
        "            if annualization_factor > 0:\n",
        "                 self.annualized_return = (1 + self.total_return)**annualization_factor - 1\n",
        "                 self.annualized_vol = self.portfolio_returns.std() * np.sqrt(252) # Volatility is based on daily returns\n",
        "                 self.sharpe_ratio = self.annualized_return / self.annualized_vol if self.annualized_vol != 0 else 0.0\n",
        "            else:\n",
        "                 # Handle case with no trading days in returns\n",
        "                 self.annualized_return = np.nan\n",
        "                 self.annualized_vol = np.nan\n",
        "                 self.sharpe_ratio = np.nan\n",
        "                 print(\"\\nNot enough trading days in the backtest period to calculate annualized metrics.\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nNot enough data points to calculate performance metrics.\")\n",
        "            self.total_return = np.nan\n",
        "            self.annualized_return = np.nan\n",
        "            self.annualized_vol = np.nan\n",
        "            self.sharpe_ratio = np.nan\n",
        "\n",
        "    def set_starting_amount(self, starting_amount):\n",
        "        self.starting_amount = starting_amount\n",
        "\n",
        "    def display_performance_metrics(self, starting_amount=None):\n",
        "        \"\"\"\n",
        "        Displays the calculated performance metrics, scaled by a starting amount.\n",
        "        Assumes calculate_performance_metrics has been called.\n",
        "        \"\"\"\n",
        "        # Use the instance's starting_amount if not provided in the method call\n",
        "        display_amount = starting_amount if starting_amount is not None else self.starting_amount\n",
        "\n",
        "        print(f\"\\n--- Performance Metrics (Starting Amount: ${display_amount}) ---\")\n",
        "        # Recalculate metrics if they are not already calculated or are NaN\n",
        "        if any(pd.isna([self.total_return, self.annualized_return, self.annualized_vol, self.sharpe_ratio])):\n",
        "             self.calculate_performance_metrics()\n",
        "\n",
        "        if not pd.isna(self.total_return):\n",
        "            print(f\"Total Return (Test): {self.total_return:.2%}\")\n",
        "            final_value = display_amount * (1 + self.total_return)\n",
        "            print(f\"Final Portfolio Value: ${final_value:.2f}\")\n",
        "        if not pd.isna(self.annualized_return):\n",
        "            print(f\"Annualized Return (Test): {self.annualized_return:.2%}\")\n",
        "        if not pd.isna(self.annualized_vol):\n",
        "            print(f\"Annualized Volatility (Test): {self.annualized_vol:.2%}\")\n",
        "        if not pd.isna(self.sharpe_ratio):\n",
        "            print(f\"Sharpe Ratio (Test): {self.sharpe_ratio:.2f}\")\n",
        "        if any(pd.isna([self.total_return, self.annualized_return, self.annualized_vol, self.sharpe_ratio])):\n",
        "             print(\"Performance metrics could not be calculated.\")\n",
        "\n",
        "\n",
        "    def plot_cum_returns(self):\n",
        "        if self.cum_returns is not None and not self.cum_returns.empty:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            # Scale the cumulative returns by the starting amount for plotting\n",
        "            (self.cum_returns * self.starting_amount).plot()\n",
        "            plt.title(f'Point-in-Time Strategy Cumulative Returns (Starting Amount: ${self.starting_amount})')\n",
        "            plt.ylabel(f'Growth of ${self.starting_amount}')\n",
        "            plt.grid()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"\\nNo cumulative returns data generated by the Backtester to plot.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f888fdac"
      },
      "source": [
        "# Modify the existing backtesting cell to create an instance of the Backtester class\n",
        "# and call its methods to run the backtest.\n",
        "\n",
        "# Instantiate the Backtester class, passing the necessary data and parameters\n",
        "backtester = Backtester(\n",
        "    price_data_close=price_data_close_all, # Use the price_data_close_all DataFrame with single-level columns\n",
        "    subset_tickers=tickers, # Use the 'tickers' variable which holds the subset\n",
        "    split_ratio=SPLIT_RATIO,\n",
        "    top_n_stocks=TOP_N_STOCKS\n",
        ")\n",
        "\n",
        "# Call the run_backtest method on the backtester instance\n",
        "backtester.set_starting_amount(STARTING_AMOUNT)\n",
        "backtester.run_backtest()\n",
        "\n",
        "# Call the calculate_performance_metrics method on the backtester instance\n",
        "backtester.display_performance_metrics()\n",
        "\n",
        "# Access and display the results and metrics stored as attributes of the backtester instance\n",
        "backtester.plot_cum_returns()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 8. Results Visualization (with Benchmark)\n",
        "# =======================\n",
        "\n",
        "# 1. Download benchmark data for the test period\n",
        "# Ensure the test_dates are correctly defined, possibly from the backtester object\n",
        "# For now, let's use the index from the backtester's cumulative returns which should represent the test period\n",
        "if backtester.cum_returns is not None and not backtester.cum_returns.empty:\n",
        "    test_period_start = backtester.cum_returns.index[0]\n",
        "    test_period_end = backtester.cum_returns.index[-1]\n",
        "else:\n",
        "    print(\"Backtester cumulative returns are not available to define the benchmark period.\")\n",
        "    # Fallback to original test_dates logic if backtester results are not ready\n",
        "    all_dates = price_data_close_all.index\n",
        "    split_idx = int(len(all_dates) * SPLIT_RATIO)\n",
        "    test_dates = all_dates[split_idx:]\n",
        "    if not test_dates.empty:\n",
        "        test_period_start = test_dates[0]\n",
        "        test_period_end = test_dates[-1]\n",
        "    else:\n",
        "        print(\"Cannot determine benchmark period.\")\n",
        "        test_period_start = None\n",
        "        test_period_end = None\n",
        "\n",
        "\n",
        "if test_period_start is not None and test_period_end is not None:\n",
        "    benchmark_ticker_data = yf.download(benchmark_ticker, start=test_period_start, end=test_period_end, auto_adjust=True, progress=False)\n",
        "    if not benchmark_ticker_data.empty:\n",
        "        benchmark_ticker_close_prices = benchmark_ticker_data['Close']\n",
        "\n",
        "        # 2. Calculate SPY's daily returns and cumulative returns\n",
        "        benchmark_returns = benchmark_ticker_close_prices.pct_change().fillna(0)\n",
        "        benchmark_cum_returns = (1 + benchmark_returns).cumprod()\n",
        "\n",
        "        # Ensure the starting value of benchmark is 1.0 for comparison\n",
        "        if not benchmark_cum_returns.empty:\n",
        "             benchmark_cum_returns = benchmark_cum_returns / benchmark_cum_returns.iloc[0]\n",
        "\n",
        "        # Align the two time series to a common index\n",
        "        # Use the cum_returns from the backtester instance\n",
        "        cum_returns_aligned = backtester.cum_returns.reindex(benchmark_cum_returns.index.union(backtester.cum_returns.index))\n",
        "        benchmark_cum_returns_aligned = benchmark_cum_returns.reindex(benchmark_cum_returns.index.union(backtester.cum_returns.index))\n",
        "        # print(cum_returns_aligned.head())\n",
        "        # print(benchmark_cum_returns_aligned.head())\n",
        "\n",
        "        # Forward fill to handle missing dates, ensuring alignment\n",
        "        cum_returns_aligned = cum_returns_aligned.ffill()\n",
        "        benchmark_cum_returns_aligned = benchmark_cum_returns_aligned.ffill()\n",
        "\n",
        "        # 3. Plot both on the same graph\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot your portfolio\n",
        "        plt.plot(cum_returns_aligned.index, cum_returns_aligned.values,\n",
        "                 label='My Portfolio', linewidth=2)\n",
        "\n",
        "        # Plot the benchmark\n",
        "        plt.plot(benchmark_cum_returns_aligned.index, benchmark_cum_returns_aligned.values,\n",
        "                 linestyle='--', label=benchmark_ticker, linewidth=2)\n",
        "\n",
        "        # Annotate final values\n",
        "        # Ensure there are non-NaN values before attempting to get the last date/value\n",
        "        if not cum_returns_aligned.dropna().empty:\n",
        "             last_portfolio_date = cum_returns_aligned.dropna().index[-1]\n",
        "             last_portfolio_value = cum_returns_aligned.dropna().iloc[-1]\n",
        "             plt.text(last_portfolio_date, last_portfolio_value,\n",
        "                     f\"{last_portfolio_value:.5}\",\n",
        "                     color='C0', fontsize=12, va='center', ha='left', fontweight='bold')\n",
        "\n",
        "        if not benchmark_cum_returns_aligned.dropna().empty:\n",
        "            last_benchmark_date = benchmark_cum_returns_aligned.dropna().index[-1]\n",
        "            last_benchmark_value = benchmark_cum_returns_aligned.dropna().iloc[-1]\n",
        "            # Handle potential Series vs scalar if only one benchmark column\n",
        "            if isinstance(last_benchmark_value, pd.Series):\n",
        "                 last_benchmark_value = last_benchmark_value.iloc[0] # Access the scalar value\n",
        "\n",
        "            plt.text(last_benchmark_date, last_benchmark_value,\n",
        "                     f\"{last_benchmark_value:.5f}\",\n",
        "                     color='C1', fontsize=12, va='center', ha='left', fontweight='bold')\n",
        "\n",
        "\n",
        "        plt.title(f'Cumulative Return: My Portfolio vs {benchmark_ticker}') # Update title\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Growth of $1')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Benchmark data download failed.\")\n",
        "else:\n",
        "    print(\"Cannot plot benchmark due to undefined period.\")"
      ],
      "metadata": {
        "id": "7h6jiBBPX_nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saves entire file to app.py"
      ],
      "metadata": {
        "id": "0KpkByvzdpny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# This entire cell will be saved as app.py\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import yfinance as yf\n",
        "import time # Import time for simulating progress\n",
        "import os # Import os for checking file existence\n",
        "\n",
        "\n",
        "# Define functions (copied from the Colab notebook)\n",
        "\n",
        "# --- Caching Configuration for S&P500 Data ---\n",
        "CACHE_FILE = 'sp500_market_caps.csv'\n",
        "\n",
        "\n",
        "# --- Helper function to download S&P 500 tickers ---\n",
        "def download_sp500_tickers(debug=True):\n",
        "    \"\"\"\n",
        "    Downloads S&P 500 tickers from Wikipedia and fetches market caps.\n",
        "    Caches the result to a CSV file.\n",
        "    \"\"\"\n",
        "    if debug and os.path.exists(CACHE_FILE):\n",
        "        # print(f\"DEBUG mode is ON. Loading data from cache file: {CACHE_FILE}\") # Moved print to streamlit logic\n",
        "        try:\n",
        "            market_caps_df = pd.read_csv(CACHE_FILE)\n",
        "            return market_caps_df\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Error loading cache file {CACHE_FILE}: {e}. Attempting to fetch live data.\")\n",
        "            # Fall through to live data fetching if cache loading fails\n",
        "\n",
        "\n",
        "    # print(f\"Fetching live data. DEBUG is OFF or cache file not found.\") # Moved print to streamlit logic\n",
        "    # Get S&P 500 tickers from Wikipedia\n",
        "    try:\n",
        "        sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "        sp500_table = pd.read_html(sp500_url)\n",
        "        sp500 = sp500_table[0]\n",
        "        # Correctly handle potential discrepancies in ticker symbols (e.g., 'BRK.B' vs 'BRK-B')\n",
        "        tickers = sp500['Symbol'].str.replace('.', '-', regex=False).tolist()\n",
        "\n",
        "        # We'll store market caps in a list of tuples\n",
        "        market_caps = []\n",
        "\n",
        "        # print(\"Downloading market cap data for S&P 500 tickers...\") # Moved print to streamlit logic\n",
        "        # Use a progress bar or spinner in Streamlit for this part\n",
        "        for ticker in tickers:\n",
        "            try:\n",
        "                info = yf.Ticker(ticker).info\n",
        "                cap = info.get('marketCap', None)\n",
        "                if cap is not None:\n",
        "                    market_caps.append((ticker, cap))\n",
        "            except Exception as e:\n",
        "                # print(f\"Could not fetch data for {ticker}: {e}\") # Keep silent for individual ticker errors\n",
        "                continue  # skip tickers with issues\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        market_caps_df = pd.DataFrame(market_caps, columns=['Ticker', 'MarketCap'])\n",
        "\n",
        "        if market_caps_df.empty:\n",
        "            st.error(\"Failed to fetch any S&P 500 market cap data.\")\n",
        "            return pd.DataFrame(columns=['Ticker', 'MarketCap'])\n",
        "\n",
        "        # Sort by market cap, descending\n",
        "        market_caps_df = market_caps_df.sort_values(by='MarketCap', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        # Save the fetched data to the cache file for future use\n",
        "        try:\n",
        "            market_caps_df.to_csv(CACHE_FILE, index=False)\n",
        "            # print(f\"Live data saved to cache file: {CACHE_FILE}\") # Moved print to streamlit logic\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Could not save market cap data to cache file {CACHE_FILE}: {e}\")\n",
        "\n",
        "\n",
        "        return market_caps_df\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error fetching S&P 500 tickers from Wikipedia: {e}\")\n",
        "        return pd.DataFrame(columns=['Ticker', 'MarketCap'])\n",
        "\n",
        "\n",
        "# --- Helper function to download price data ---\n",
        "def download_price_data(tickers, start_date, end_date):\n",
        "    \"\"\"Downloads historical price data for a list of tickers.\"\"\"\n",
        "    try:\n",
        "        # Use a progress bar or spinner in Streamlit for this part\n",
        "        price_data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker', auto_adjust=True, progress=False)\n",
        "        if price_data.empty:\n",
        "            st.warning(f\"No price data downloaded for tickers: {tickers}\")\n",
        "            return pd.DataFrame() # Return empty DataFrame\n",
        "        return price_data\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading price data for tickers {tickers}: {e}\")\n",
        "        return pd.DataFrame() # Return empty DataFrame\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 5. Factor Calculation (Value, Momentum) - Refactored\n",
        "# =======================\n",
        "\n",
        "class Factor:\n",
        "    \"\"\"Base class for financial factors.\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def calculate(self, price_data_close, tickers):\n",
        "        \"\"\"\n",
        "        Calculates the factor for the given tickers using point-in-time price data.\n",
        "        Must be implemented by subclasses.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclass must implement abstract method\")\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_factors(price_data_close, subset_tickers, factors):\n",
        "        \"\"\"\n",
        "        Calculates specified factors for a subset of tickers using point-in-time data.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices with tickers as columns.\n",
        "            subset_tickers (list): List of tickers to calculate factors for.\n",
        "            factors (list): List of Factor objects to calculate.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with factors as columns and tickers as index.\n",
        "        \"\"\"\n",
        "        factor_data = {}\n",
        "        valid_tickers_with_data = [\n",
        "            ticker for ticker in subset_tickers if ticker in price_data_close.columns and not price_data_close[ticker].dropna().empty\n",
        "        ]\n",
        "        # print(f\"Calculating factors for {len(valid_tickers_with_data)} valid tickers...\") # Moved to streamlit logic\n",
        "\n",
        "        for factor in factors:\n",
        "            factor_values = []\n",
        "            # print(f\"  Calculating {factor.name}...\") # Moved to streamlit logic\n",
        "            for ticker in valid_tickers_with_data:\n",
        "                try:\n",
        "                    # Pass relevant data to the factor's calculate method\n",
        "                    value = factor.calculate(price_data_close[[ticker]].copy(), [ticker]) # Pass single ticker DataFrame\n",
        "                    factor_values.append(value)\n",
        "                except Exception as e:\n",
        "                    # print(f\"    Error calculating {factor.name} for {ticker}: {e}\") # Keep silent for individual ticker errors\n",
        "                    factor_values.append(np.nan) # Append NaN if calculation fails\n",
        "\n",
        "            factor_data[factor.name] = factor_values\n",
        "\n",
        "        factor_df = pd.DataFrame(factor_data, index=valid_tickers_with_data)\n",
        "        factor_df = factor_df.dropna() # Drop tickers with NaN in any factor\n",
        "\n",
        "        # print(f\"Factor DataFrame after calculation and dropna:\\n{factor_df.head()}\") # Moved to streamlit logic\n",
        "\n",
        "        return factor_df\n",
        "\n",
        "\n",
        "class Value(Factor):\n",
        "    \"\"\"Value factor based on Trailing P/E ratio.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__('pe_ratio')\n",
        "\n",
        "    def calculate(self, price_data_close, tickers):\n",
        "        \"\"\"\n",
        "        Calculates the Trailing P/E ratio for a given ticker.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices for a single ticker.\n",
        "            tickers (list): A list containing the single ticker symbol.\n",
        "\n",
        "        Returns:\n",
        "            float: The Trailing P/E ratio or np.nan if unavailable.\n",
        "        \"\"\"\n",
        "        if not tickers or not isinstance(tickers, list) or len(tickers) != 1:\n",
        "            # print(\"Value factor requires a single ticker.\") # Moved print to streamlit logic\n",
        "            return np.nan\n",
        "        ticker = tickers[0]\n",
        "        try:\n",
        "            info = yf.Ticker(ticker).info\n",
        "            pe_ratio = info.get('trailingPE', np.nan)\n",
        "            # print(f\"  PE for {ticker}: {pe_ratio}\") # Moved print to streamlit logic\n",
        "            return pe_ratio\n",
        "        except Exception as e:\n",
        "            # print(f\"  Error fetching PE for {ticker}: {e}\") # Keep silent for individual ticker errors\n",
        "            return np.nan\n",
        "\n",
        "\n",
        "class Momentum(Factor):\n",
        "    \"\"\"Momentum factor based on 6-month price return.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__('6m_return')\n",
        "\n",
        "    def calculate(self, price_data_close, tickers):\n",
        "        \"\"\"\n",
        "        Calculates the 6-month price return for a given ticker.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices for a single ticker.\n",
        "            tickers (list): A list containing the single ticker symbol.\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            float: The 6-month return or np.nan if insufficient data.\n",
        "        \"\"\"\n",
        "        if not tickers or not isinstance(tickers, list) or len(tickers) != 1:\n",
        "            # print(\"Momentum factor requires a single ticker.\") # Moved print to streamlit logic\n",
        "            return np.nan\n",
        "        ticker = tickers[0]\n",
        "        try:\n",
        "            # Ensure the price_data_close for the single ticker is a Series\n",
        "            prices = price_data_close[ticker].dropna()\n",
        "            # print(f\"  Prices length for {ticker}: {len(prices)}\") # Moved to streamlit logic\n",
        "            if len(prices) > 126: # Approximately 6 months of trading days\n",
        "                return_6m = (prices.iloc[-1] / prices.iloc[-126]) - 1\n",
        "                # print(f\"  6m return for {ticker}: {return_6m}\") # Moved to streamlit logic\n",
        "                return return_6m\n",
        "            else:\n",
        "                return np.nan\n",
        "        except Exception as e:\n",
        "            # print(f\"  Error calculating 6m return for {ticker}: {e}\") # Keep silent for individual ticker errors\n",
        "            return np.nan\n",
        "\n",
        "# =======================\n",
        "# 6. Composite Scoring & Stock Selection\n",
        "# =======================\n",
        "\n",
        "class StockSelector:\n",
        "    \"\"\"Handles composite scoring and stock selection based on factor data.\"\"\"\n",
        "\n",
        "    def __init__(self, factor_df, num_stocks_to_select):\n",
        "        \"\"\"\n",
        "        Initializes the StockSelector.\n",
        "\n",
        "        Args:\n",
        "            factor_df (pd.DataFrame): DataFrame with factors as columns and tickers as index.\n",
        "            num_stocks_to_select (int): The number of top stocks to select.\n",
        "        \"\"\"\n",
        "        self.factor_df = factor_df.copy() # Work on a copy to avoid modifying the original\n",
        "        self.num_stocks_to_select = num_stocks_to_select\n",
        "        self.selected_tickers = []\n",
        "\n",
        "    def perform_selection(self):\n",
        "        \"\"\"\n",
        "        Performs composite scoring and selects the top N stocks.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of selected ticker symbols.\n",
        "        \"\"\"\n",
        "        if self.factor_df.empty:\n",
        "            # print(\"Factor DataFrame is empty. Cannot perform selection.\") # Moved print to streamlit logic\n",
        "            return []\n",
        "\n",
        "        # Ensure 'pe_ratio' and '6m_return' columns exist before ranking\n",
        "        if 'pe_ratio' in self.factor_df.columns and '6m_return' in self.factor_df.columns:\n",
        "            # Rank: lower P/E is better, higher momentum is better\n",
        "            # Handle NaNs in ranking by pushing them to the bottom (worst rank)\n",
        "            self.factor_df['pe_rank'] = self.factor_df['pe_ratio'].rank(ascending=True, na_option='bottom')\n",
        "            self.factor_df['mom_rank'] = self.factor_df['6m_return'].rank(ascending=False, na_option='bottom')\n",
        "\n",
        "            # Simple equal-weight composite score\n",
        "            # Fill NaNs in ranks with a value larger than any possible rank to ensure they get the worst composite score\n",
        "            max_rank = self.factor_df.shape[0]\n",
        "            self.factor_df['composite_score'] = (self.factor_df['pe_rank'].fillna(max_rank + 1) + self.factor_df['mom_rank'].fillna(max_rank + 1)) / 2\n",
        "\n",
        "            # Select top N stocks\n",
        "            # Ensure there are enough stocks to select num_stocks_to_select\n",
        "            if not self.factor_df.empty and self.factor_df.shape[0] >= self.num_stocks_to_select:\n",
        "                 selected = self.factor_df.nsmallest(self.num_stocks_to_select, 'composite_score')\n",
        "                 self.selected_tickers = selected.index.tolist()\n",
        "                 # print(f\"Selected top {self.num_stocks_to_select} stocks: {self.selected_tickers}\") # Moved print to streamlit logic\n",
        "            elif not self.factor_df.empty:\n",
        "                 # If fewer than num_stocks_to_select are available, select all available\n",
        "                 self.selected_tickers = self.factor_df.nsmallest(self.factor_df.shape[0], 'composite_score').index.tolist()\n",
        "                 # print(f\"Selected {len(self.selected_tickers)} stocks (fewer than requested {self.num_stocks_to_select}): {self.selected_tickers}\") # Moved print to streamlit logic\n",
        "            else:\n",
        "                # print(\"No stocks available for selection after scoring.\") # Moved print to streamlit logic\n",
        "                self.selected_tickers = []\n",
        "        else:\n",
        "            # print(\"Required factor columns ('pe_ratio', '6m_return') not found in factor_df for scoring.\") # Moved print to streamlit logic\n",
        "            self.selected_tickers = []\n",
        "\n",
        "        return self.selected_tickers\n",
        "\n",
        "# =======================\n",
        "# 7. Backtesting (Refactored into Class)\n",
        "# =======================\n",
        "class Backtester:\n",
        "    \"\"\"\n",
        "    Encapsulates the backtesting logic for a factor-based strategy.\n",
        "    \"\"\"\n",
        "    def __init__(self, price_data_close, subset_tickers, split_ratio, top_n_stocks, rebalance_freq='QS'):\n",
        "        \"\"\"\n",
        "        Splits data, calculates rebalance dates.\n",
        "\n",
        "        Args:\n",
        "            price_data_close (pd.DataFrame): DataFrame of 'Close' prices with tickers as columns.\n",
        "            subset_tickers (list): List of tickers to consider for selection.\n",
        "            split_ratio (float): Ratio of data to use for training (defines the start of the test period).\n",
        "            top_n_stocks (int): The number of top stocks to select at each rebalance.\n",
        "            rebalance_freq (str): Frequency string for rebalancing (e.g., 'QS' for quarterly).\n",
        "        \"\"\"\n",
        "        self.price_data_close = price_data_close.copy()\n",
        "        self.subset_tickers = subset_tickers\n",
        "        self.split_ratio = split_ratio\n",
        "        self.top_n_stocks = top_n_stocks\n",
        "        self.rebalance_freq = rebalance_freq\n",
        "        self.starting_amount = 1 # default starting portfolio value is $1\n",
        "        self.rebalance_dates = None\n",
        "        self.selected_tickers = None\n",
        "\n",
        "        # Initialize attributes to store results\n",
        "        self.portfolio_returns = None\n",
        "        self.cum_returns = None\n",
        "        self.total_return = None\n",
        "        self.annualized_return = None\n",
        "        self.annualized_vol = None\n",
        "        self.sharpe_ratio = None\n",
        "\n",
        "    def _get_test_period_dates(self):\n",
        "        \"\"\"\n",
        "        Identifies and returns the test period dates based on the split ratio.\n",
        "\n",
        "        Returns:\n",
        "            pd.DatetimeIndex: A DatetimeIndex containing the dates for the test period.\n",
        "        \"\"\"\n",
        "        all_dates = self.price_data_close.index\n",
        "        split_idx = int(len(all_dates) * self.split_ratio)\n",
        "        test_dates = all_dates[split_idx:]\n",
        "        return test_dates\n",
        "\n",
        "\n",
        "    def _calculate_rebalance_dates(self, test_dates):\n",
        "        \"\"\"\n",
        "        Calculates the dates on which to rebalance the portfolio.\n",
        "\n",
        "        Args:\n",
        "            test_dates (pd.DatetimeIndex): The dates for the test period.\n",
        "\n",
        "        Returns:\n",
        "            pd.DatetimeIndex: A DatetimeIndex containing the rebalance dates.\n",
        "        \"\"\"\n",
        "        if test_dates.empty:\n",
        "             # print(\"Warning: Test period is empty. Adjust split ratio or data years.\") # Moved print to streamlit logic\n",
        "             return pd.DatetimeIndex([]) # Return an empty DatetimeIndex\n",
        "\n",
        "\n",
        "        test_start_date, test_end_date = test_dates[0], test_dates[-1]\n",
        "        rebalance_dates = pd.date_range(start=test_start_date, end=test_end_date, freq=self.rebalance_freq)\n",
        "\n",
        "        # Ensure the first day of the test period is included if it's not a quarter start\n",
        "        if test_start_date not in rebalance_dates:\n",
        "            rebalance_dates = rebalance_dates.insert(0, test_start_date)\n",
        "        return rebalance_dates\n",
        "\n",
        "\n",
        "    def _perform_point_in_time_analysis(self, current_date):\n",
        "        \"\"\"\n",
        "        Extracts point-in-time data, calculates factors, and selects top stocks for a given date.\n",
        "\n",
        "        Args:\n",
        "            current_date (pd.Timestamp): The date for which to perform the analysis.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of selected ticker symbols for the current period, or an empty list if selection fails.\n",
        "        \"\"\"\n",
        "        # print(f\"\\nRebalancing for period starting {current_date.date()}...\") # Moved print to streamlit logic\n",
        "        point_in_time_data = self.price_data_close[self.price_data_close.index <= current_date]\n",
        "\n",
        "        if point_in_time_data.empty:\n",
        "            # print(\"  -> Skipping: Not enough historical data to calculate factors.\") # Moved print to streamlit logic\n",
        "            return []\n",
        "\n",
        "        # print(f\"Analysing point in time data from {point_in_time_data.index[0].date()} to {point_in_time_data.index[-1].date()}\") # Moved print to streamlit logic\n",
        "\n",
        "        # Recalculate factors using only point-in-time data\n",
        "        value_factor = Value() # Assuming Value and Momentum classes are available\n",
        "        momentum_factor = Momentum()\n",
        "        factors_to_calculate = [Value(), Momentum()]\n",
        "\n",
        "        # Use the calculate_factors static method from the Factor class\n",
        "        factor_df_point_in_time = Factor.calculate_factors(point_in_time_data, self.subset_tickers, factors_to_calculate)\n",
        "\n",
        "\n",
        "        if factor_df_point_in_time.empty:\n",
        "            # print(\"  -> Skipping: No valid tickers after factor calculation.\") # Moved print to streamlit logic\n",
        "            return []\n",
        "\n",
        "        # Perform Composite Scoring and Select Top N stocks based on the point-in-time factor_df\n",
        "        stock_selector_point_in_time = StockSelector(factor_df_point_in_time, self.top_n_stocks)\n",
        "        current_period_selected_tickers = stock_selector_point_in_time.perform_selection()\n",
        "\n",
        "        if not current_period_selected_tickers:\n",
        "             # print(f\"  -> No stocks selected for period starting {current_date.date()}.\") # Moved print to streamlit logic\n",
        "             return [] # No stocks selected for this period\n",
        "        else:\n",
        "            # print(f\"  -> New portfolio selected for period starting {current_date.date()}: {current_period_selected_tickers}\") # Moved print to streamlit logic\n",
        "            return current_period_selected_tickers\n",
        "\n",
        "\n",
        "    def _calculate_holding_period_returns(self, start_date, end_date, selected_tickers):\n",
        "        \"\"\"\n",
        "        Calculates the returns for a given holding period and selected tickers.\n",
        "\n",
        "        Args:\n",
        "            start_date (pd.Timestamp): The start date of the holding period.\n",
        "            end_date (pd.Timestamp): The end date of the holding period.\n",
        "            selected_tickers (list): A list of ticker symbols held during the period.\n",
        "\n",
        "        Returns:\n",
        "            pd.Series: A time series of equal-weighted daily returns for the holding period, or an empty Series if no data.\n",
        "        \"\"\"\n",
        "        if not selected_tickers:\n",
        "            return pd.Series()\n",
        "\n",
        "        holding_period_mask = (self.price_data_close.index >= start_date) & (self.price_data_close.index < end_date)\n",
        "        holding_period_prices = self.price_data_close[holding_period_mask]\n",
        "\n",
        "        if not holding_period_prices.empty and selected_tickers:\n",
        "            valid_tickers_in_holding_period = [t for t in selected_tickers if t in holding_period_prices.columns]\n",
        "            if valid_tickers_in_holding_period:\n",
        "                period_prices_selected = holding_period_prices[valid_tickers_in_holding_period]\n",
        "                period_returns = period_prices_selected.pct_change().fillna(0)\n",
        "                # Assume equal weight for the period\n",
        "                equal_weight_returns = period_returns.mean(axis=1)\n",
        "                return equal_weight_returns\n",
        "            else:\n",
        "                # print(f\"  -> No valid selected tickers found in price data for holding period starting {start_date.date()}.\") # Moved print to streamlit logic\n",
        "                return pd.Series(index=holding_period_prices.index) # Return empty series with correct index\n",
        "        else:\n",
        "            # print(f\"  -> No data for holding period starting {start_date.date()}.\") # Moved print to streamlit logic\n",
        "            return pd.Series() # Return empty series\n",
        "\n",
        "\n",
        "    def _concatenate_and_process_returns(self, all_period_returns, test_dates):\n",
        "        \"\"\"\n",
        "        Concatenates all period returns, calculates cumulative returns, reindexes, and forward fills.\n",
        "\n",
        "        Args:\n",
        "            all_period_returns (list): A list of pandas Series, each containing returns for a holding period.\n",
        "            test_dates (pd.DatetimeIndex): The full range of test period dates.\n",
        "        \"\"\"\n",
        "        if all_period_returns:\n",
        "            self.portfolio_returns = pd.concat(all_period_returns).sort_index()\n",
        "            self.portfolio_returns = self.portfolio_returns[~self.portfolio_returns.index.duplicated(keep='first')]\n",
        "\n",
        "            # 5. Calculate final cumulative returns\n",
        "            self.cum_returns = (1 + self.portfolio_returns).cumprod()\n",
        "\n",
        "            # Prepend a starting value of 1 at the very beginning of the test period\n",
        "            actual_start_date = self.portfolio_returns.index[0] if not self.portfolio_returns.empty else test_dates[0]\n",
        "            start_value_series = pd.Series([1.0], index=[actual_start_date - pd.Timedelta(days=1)])\n",
        "            self.cum_returns = pd.concat([start_value_series, self.cum_returns])\n",
        "\n",
        "            # Reindex to the full test_dates and forward fill\n",
        "            self.cum_returns = self.cum_returns.reindex(test_dates)\n",
        "            self.cum_returns = self.cum_returns.ffill()\n",
        "\n",
        "            # print(\"\\n--- Backtest Returns Processed ---\") # Moved print to streamlit logic\n",
        "        else:\n",
        "            # print(\"\\nBacktest could not be completed. No returns were generated.\") # Moved print to streamlit logic\n",
        "            self.portfolio_returns = pd.Series(index=test_dates if test_dates is not None and not test_dates.empty else None)\n",
        "            self.cum_returns = pd.Series(index=test_dates if test_dates is not None and not test_dates.empty else None)\n",
        "\n",
        "\n",
        "\n",
        "    def run_backtest(self):\n",
        "        \"\"\"\n",
        "        Runs the point-in-time backtesting loop with quarterly rebalancing.\n",
        "        \"\"\"\n",
        "        test_dates = self._get_test_period_dates()\n",
        "        rebalance_dates = self._calculate_rebalance_dates(test_dates)\n",
        "\n",
        "        if rebalance_dates.empty: # Check for empty DatetimeIndex\n",
        "            # print(\"No rebalance dates available\") # Moved print to streamlit logic\n",
        "            # Ensure returns are initialized if no rebalance dates\n",
        "            self.portfolio_returns = pd.Series(index=test_dates if test_dates is not None and not test_dates.empty else None)\n",
        "            self.cum_returns = pd.Series(index=test_dates if test_dates is not None and not test_dates.empty else None)\n",
        "            return\n",
        "\n",
        "        # Loop through rebalance dates to simulate the strategy\n",
        "        all_period_returns = []\n",
        "        last_rebalance_date = None\n",
        "        last_selected_tickers = []\n",
        "\n",
        "        # print(f\"Starting point-in-time backtest with {len(rebalance_dates)} rebalance periods...\") # Moved print to streamlit logic\n",
        "\n",
        "        for i, rebalance_date in enumerate(rebalance_dates):\n",
        "            if last_rebalance_date is not None and last_selected_tickers:\n",
        "                # Calculate returns for the previously selected portfolio during the last holding period\n",
        "                holding_period_returns = self._calculate_holding_period_returns(last_rebalance_date, rebalance_date, last_selected_tickers)\n",
        "                if not holding_period_returns.empty:\n",
        "                    all_period_returns.append(holding_period_returns)\n",
        "\n",
        "\n",
        "            # --- Point-in-Time Analysis for the current rebalance_date ---\n",
        "            current_period_selected_tickers = self._perform_point_in_time_analysis(rebalance_date)\n",
        "\n",
        "            last_selected_tickers = current_period_selected_tickers\n",
        "            last_rebalance_date = rebalance_date\n",
        "\n",
        "        # After the loop, process the returns from the last holding period\n",
        "        if last_rebalance_date is not None and last_selected_tickers and test_dates is not None and not test_dates.empty:\n",
        "            final_holding_period_returns = self._calculate_holding_period_returns(last_rebalance_date, test_dates[-1] + pd.Timedelta(days=1), last_selected_tickers) # Add a day to include the last day\n",
        "            if not final_holding_period_returns.empty:\n",
        "                all_period_returns.append(final_holding_period_returns)\n",
        "\n",
        "        # Concatenate and process all collected returns\n",
        "        self._concatenate_and_process_returns(all_period_returns, test_dates)\n",
        "\n",
        "\n",
        "    def calculate_performance_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculates and stores key performance metrics.\n",
        "        Assumes run_backtest has been called and self.portfolio_returns and self.cum_returns are populated.\n",
        "        \"\"\"\n",
        "        print(f\"Calculating metrics. Portfolio Returns empty: {self.portfolio_returns.empty if self.portfolio_returns is not None else True}\")\n",
        "        print(f\"Calculating metrics. Cum Returns empty: {self.cum_returns.empty if self.cum_returns is not None else True}\")\n",
        "        print(f\"Calculating metrics. Cum Returns length: {len(self.cum_returns) if self.cum_returns is not None else 0}\")\n",
        "\n",
        "\n",
        "        if self.portfolio_returns is None or self.portfolio_returns.empty or self.cum_returns is None or len(self.cum_returns) <= 1:\n",
        "            print(\"\\nNot enough data to calculate performance metrics.\")\n",
        "            self.total_return = np.nan\n",
        "            self.annualized_return = np.nan\n",
        "            self.annualized_vol = np.nan\n",
        "            self.sharpe_ratio = np.nan\n",
        "            return\n",
        "\n",
        "        # Ensure metrics are calculated on the non-NaN parts of the cumulative returns series\n",
        "        if not self.cum_returns.dropna().empty and len(self.cum_returns.dropna()) > 1:\n",
        "            self.total_return = self.cum_returns.dropna().iloc[-1] - 1\n",
        "\n",
        "            # Calculate duration based on the actual number of trading days in the portfolio_returns series\n",
        "            duration_trading_days = len(self.portfolio_returns.dropna()) # Use dropna() here too\n",
        "            annualization_factor = 252 / duration_trading_days if duration_trading_days > 0 else 0\n",
        "\n",
        "            if annualization_factor > 0:\n",
        "                 self.annualized_return = (1 + self.total_return)**annualization_factor - 1\n",
        "                 self.annualized_vol = self.portfolio_returns.std() * np.sqrt(252) # Volatility is based on daily returns\n",
        "                 # Check if annualized_vol is not zero before calculating Sharpe Ratio\n",
        "                 self.sharpe_ratio = self.annualized_return / self.annualized_vol if self.annualized_vol != 0 and not pd.isna(self.annualized_vol) else 0.0 # Add isnan check\n",
        "\n",
        "            else:\n",
        "                 # Handle case with no trading days in returns\n",
        "                 self.total_return = np.nan # Set total return to NaN too\n",
        "                 self.annualized_return = np.nan\n",
        "                 self.annualized_vol = np.nan\n",
        "                 self.sharpe_ratio = np.nan\n",
        "                 print(\"\\nNot enough trading days in the backtest period to calculate annualized metrics.\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nNot enough data points to calculate performance metrics.\")\n",
        "            self.total_return = np.nan\n",
        "            self.annualized_return = np.nan\n",
        "            self.annualized_vol = np.nan\n",
        "            self.sharpe_ratio = np.nan\n",
        "\n",
        "    def set_starting_amount(self, starting_amount):\n",
        "        self.starting_amount = starting_amount\n",
        "\n",
        "    def display_performance_metrics(self, starting_amount=None):\n",
        "        \"\"\"\n",
        "        Displays the calculated performance metrics, scaled by a starting amount.\n",
        "        Assumes calculate_performance_metrics has been called.\n",
        "        \"\"\"\n",
        "        # Use the instance's starting_amount if not provided in the method call\n",
        "        display_amount = starting_amount if starting_amount is not None else self.starting_amount\n",
        "\n",
        "        # print(f\"\\n--- Performance Metrics (Starting Amount: ${display_amount}) ---\") # Moved print to streamlit logic\n",
        "        # Recalculate metrics if they are not already calculated or are NaN\n",
        "        if any(pd.isna([self.total_return, self.annualized_return, self.annualized_vol, self.sharpe_ratio])):\n",
        "             self.calculate_performance_metrics()\n",
        "\n",
        "        # Moved print statements to streamlit logic for displaying metrics\n",
        "\n",
        "    def plot_cum_returns(self):\n",
        "        if self.cum_returns is not None and not self.cum_returns.empty:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            # Scale the cumulative returns by the starting amount for plotting\n",
        "            (self.cum_returns * self.starting_amount).plot()\n",
        "            plt.title(f'Point-in-Time Strategy Cumulative Returns (Starting Amount: ${self.starting_amount})')\n",
        "            plt.ylabel(f'Growth of ${self.starting_amount}')\n",
        "            plt.grid()\n",
        "            plt.show()\n",
        "        else:\n",
        "            # print(\"\\nNo cumulative returns data generated by the Backtester to plot.\") # Moved print to streamlit logic\n",
        "            pass\n",
        "\n",
        "\n",
        "# --- Helper functions for Streamlit UI interactions ---\n",
        "\n",
        "@st.cache_data # Cache the data fetching and initial processing\n",
        "def load_data(data_years, subset_tickers, debug_mode):\n",
        "    \"\"\"Loads S&P 500 tickers and historical price data.\"\"\"\n",
        "    end_date = datetime.today()\n",
        "    start_date = end_date - timedelta(days=365 * data_years)\n",
        "\n",
        "    market_caps_df = download_sp500_tickers(debug=debug_mode)\n",
        "    if market_caps_df.empty:\n",
        "        return None, None\n",
        "\n",
        "    all_tickers = market_caps_df['Ticker'].tolist()\n",
        "    tickers_to_download = all_tickers[:subset_tickers] # Use the subset size from parameters\n",
        "\n",
        "    price_data = download_price_data(tickers_to_download, start_date, end_date)\n",
        "    if price_data.empty:\n",
        "        return None, None\n",
        "\n",
        "    # Explicitly extract only 'Close' prices and create a new DataFrame with simple columns\n",
        "    if isinstance(price_data.columns, pd.MultiIndex):\n",
        "         # Select 'Close' for all tickers in subset_tickers\n",
        "         price_data_close = price_data.loc[:, (tickers_to_download, 'Close')]\n",
        "         # Drop the 'Price' level to have tickers as single-level columns\n",
        "         price_data_close.columns = price_data_close.columns.droplevel('Price')\n",
        "    else: # Handle case where price_data might not have a MultiIndex (e.g., single ticker download)\n",
        "         # Assuming it's already the close series for a single ticker, convert to DataFrame\n",
        "         price_data_close = pd.DataFrame(price_data)\n",
        "         if tickers_to_download:\n",
        "             price_data_close.columns = [tickers_to_download[0]] # Set the ticker as the column name\n",
        "         else:\n",
        "             return None, None # Should not happen if market_caps_df is not empty\n",
        "\n",
        "\n",
        "    return price_data_close, tickers_to_download # Return the filtered tickers used\n",
        "\n",
        "\n",
        "# --- Main Streamlit App Logic ---\n",
        "\n",
        "# Set the title of the Streamlit application\n",
        "st.title('Stock Backtesting Strategy')\n",
        "\n",
        "# Create a section for parameter inputs\n",
        "st.header('Backtesting Parameters')\n",
        "with st.expander(\"Adjust Parameters\"):\n",
        "    st.write(\"Configure the parameters for the backtesting simulation.\")\n",
        "\n",
        "    # Add DEBUG checkbox\n",
        "    debug_mode = st.checkbox('Debug Mode (Load S&P 500 tickers from storage)', value=True, help=\"If checked, attempt to load S&P 500 tickers from a local file cache first.\")\n",
        "\n",
        "\n",
        "    # Input widget for SPLIT_RATIO\n",
        "    split_ratio_input = st.number_input(\n",
        "        'Train/Test Split Ratio',\n",
        "        min_value=0.1,\n",
        "        max_value=0.9,\n",
        "        value=0.7,\n",
        "        step=0.05,\n",
        "        help=\"Ratio of data to use for training (e.g., 0.7 for 70% train, 30% test)\"\n",
        "    )\n",
        "\n",
        "    # Input widget for DATA_YEARS\n",
        "    data_years_input = st.number_input(\n",
        "        'Number of Years of Data',\n",
        "        min_value=1,\n",
        "        max_value=10,\n",
        "        value=2,\n",
        "        step=1,\n",
        "        help=\"Number of years of historical data to download\"\n",
        "    )\n",
        "\n",
        "    # Input widget for TOP_N_STOCKS\n",
        "    top_n_stocks_input = st.number_input(\n",
        "        'Top N Stocks to Select',\n",
        "        min_value=1,\n",
        "        max_value=50,\n",
        "        value=5,\n",
        "        step=1,\n",
        "        help=\"Number of top-ranked stocks to include in the portfolio\"\n",
        "    )\n",
        "\n",
        "    # Input widget for Subset Tickers size\n",
        "    subset_tickers_input = st.number_input(\n",
        "        'Number of S&P 500 Tickers to Consider',\n",
        "        min_value=10,\n",
        "        max_value=500, # Max should be number of tickers available\n",
        "        value=50,\n",
        "        step=10,\n",
        "        help=\"Number of largest S&P 500 tickers to consider for the backtest.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Define the main logic to run when parameters change\n",
        "if st.button('Run Backtest'):\n",
        "    # Load data using the cached function\n",
        "    with st.spinner(f\"Loading data for {data_years_input} years...\"):\n",
        "        price_data_close, tickers_to_backtest = load_data(data_years_input, subset_tickers_input, debug_mode)\n",
        "\n",
        "\n",
        "    if price_data_close is None or tickers_to_backtest is None or price_data_close.empty or not tickers_to_backtest:\n",
        "        st.error(\"Failed to load necessary data. Please check your parameters and try again.\")\n",
        "        st.stop()\n",
        "\n",
        "    # Instantiate the Backtester class\n",
        "    backtester = Backtester(\n",
        "        price_data_close=price_data_close,\n",
        "        subset_tickers=tickers_to_backtest,\n",
        "        split_ratio=split_ratio_input,\n",
        "        top_n_stocks=top_n_stocks_input\n",
        "    )\n",
        "\n",
        "    # Run the backtest\n",
        "    with st.spinner(\"Running backtest...\"):\n",
        "         backtester.run_backtest()\n",
        "\n",
        "\n",
        "    if backtester.cum_returns is None or backtester.cum_returns.empty:\n",
        "         st.warning(\"Backtest did not produce cumulative returns. Check data availability and parameters.\")\n",
        "         st.stop()\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    backtester.calculate_performance_metrics()\n",
        "\n",
        "\n",
        "    # Download SPY data for benchmark\n",
        "    spy_ticker = '^GSPC'\n",
        "    benchmark_cum_returns = pd.Series() # Initialize as empty\n",
        "    benchmark_returns = pd.Series() # Initialize as empty\n",
        "\n",
        "    try:\n",
        "        with st.spinner(\"Downloading benchmark data...\"):\n",
        "            # Download benchmark data for the specific test period\n",
        "            # Ensure benchmark data aligns with the portfolio's test period index\n",
        "            test_period_start = backtester.cum_returns.index[0] if not backtester.cum_returns.empty else datetime.today() - timedelta(days=365 * data_years_input * (1 - split_ratio_input))\n",
        "            test_period_end = backtester.cum_returns.index[-1] if not backtester.cum_returns.empty else datetime.today()\n",
        "\n",
        "\n",
        "            benchmark_data = yf.download(spy_ticker, start=test_period_start, end=test_period_end, auto_adjust=True, progress=False)\n",
        "\n",
        "        if not benchmark_data.empty:\n",
        "             benchmark_returns = benchmark_data['Close'].pct_change().fillna(0)\n",
        "             benchmark_cum_returns = (1 + benchmark_returns).cumprod()\n",
        "\n",
        "            # Align the two time series to a common index, forward filling missing values\n",
        "             common_index = backtester.cum_returns.index.union(benchmark_cum_returns.index)\n",
        "             cum_returns_aligned = backtester.cum_returns.reindex(common_index).fillna(method='ffill')\n",
        "             benchmark_cum_returns_aligned = benchmark_cum_returns.reindex(common_index).fillna(method='ffill')\n",
        "\n",
        "        else:\n",
        "            st.warning(\"Benchmark data download failed. Skipping benchmark in plots and metrics.\")\n",
        "            # If benchmark fails, ensure cum_returns_aligned still holds the portfolio data\n",
        "            cum_returns_aligned = backtester.cum_returns.reindex(backtester.cum_returns.index)\n",
        "            benchmark_cum_returns_aligned = pd.Series(index=backtester.cum_returns.index) # Empty series for benchmark\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "         st.warning(f\"Could not download benchmark data or align: {e}. Skipping benchmark.\")\n",
        "         # If benchmark fails, ensure cum_returns_aligned still holds the portfolio data\n",
        "         cum_returns_aligned = backtester.cum_returns.reindex(backtester.cum_returns.index)\n",
        "         benchmark_cum_returns_aligned = pd.Series(index=backtester.cum_returns.index) # Empty series for benchmark\n",
        "         benchmark_returns = pd.Series(index=backtester.cum_returns.index) # Initialize benchmark_returns to empty Series in case of error\n",
        "\n",
        "\n",
        "    # --- Results Visualization (Interactive Graph) ---\n",
        "    st.header('Cumulative Returns')\n",
        "    st.write(\"Visualize the cumulative returns of the selected portfolio vs. a benchmark.\")\n",
        "\n",
        "    if cum_returns_aligned is not None and not cum_returns_aligned.empty:\n",
        "        # Create a DataFrame for plotting\n",
        "        plot_df = pd.DataFrame({\n",
        "            'Date': cum_returns_aligned.index,\n",
        "            'My Portfolio': cum_returns_aligned.values\n",
        "        })\n",
        "\n",
        "        if benchmark_cum_returns_aligned is not None and not benchmark_cum_returns_aligned.empty:\n",
        "             # Only add benchmark if it's not an empty series\n",
        "             # Ensure benchmark_cum_returns_aligned is not all NaNs before adding\n",
        "             if not benchmark_cum_returns_aligned.dropna().empty:\n",
        "                plot_df['S&P 500'] = benchmark_cum_returns_aligned.values\n",
        "\n",
        "        if not plot_df.empty:\n",
        "             # Reshape the DataFrame for Plotly\n",
        "             plot_df_melted = plot_df.melt(\n",
        "                 'Date',\n",
        "                 var_name='Strategy',\n",
        "                 value_name='Cumulative Returns'\n",
        "             )\n",
        "\n",
        "             # Create the interactive Plotly line chart\n",
        "             fig = px.line(\n",
        "                 plot_df_melted,\n",
        "                 x='Date',\n",
        "                 y='Cumulative Returns',\n",
        "                 color='Strategy',\n",
        "                 title='Cumulative Return: My Portfolio vs S&P 500'\n",
        "             )\n",
        "\n",
        "             # Display the Plotly figure in Streamlit\n",
        "             st.plotly_chart(fig, use_container_width=True)\n",
        "        else:\n",
        "             st.warning(\"No valid data points to plot.\")\n",
        "\n",
        "    else:\n",
        "        st.warning(\"No cumulative returns data to plot.\")\n",
        "\n",
        "    # --- Performance Metrics ---\n",
        "    st.header('Performance Metrics')\n",
        "    st.write(\"Key performance indicators for the backtested strategy.\")\n",
        "\n",
        "    # Ensure we have enough data to calculate metrics\n",
        "    if backtester.portfolio_returns is not None and not backtester.portfolio_returns.empty and backtester.cum_returns is not None and len(backtester.cum_returns) > 1:\n",
        "        # --- Create Columns for Display ---\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        # --- Portfolio Calculations ---\n",
        "        with col1:\n",
        "            st.subheader(\"My Portfolio\")\n",
        "            # Use the metrics calculated and stored in the backtester instance\n",
        "            if not pd.isna(backtester.total_return):\n",
        "                 st.metric(label=\"Total Return\", value=f\"{backtester.total_return:.2%}\")\n",
        "                 final_value = 10000 * (1 + backtester.total_return) # Display with a starting amount of $10000\n",
        "                 st.metric(label=\"Final Portfolio Value ($10k start)\", value=f\"${final_value:.2f}\")\n",
        "\n",
        "            if not pd.isna(backtester.annualized_return):\n",
        "                st.metric(label=\"Annualized Return\", value=f\"{backtester.annualized_return:.2%}\")\n",
        "            if not pd.isna(backtester.annualized_vol):\n",
        "                st.metric(label=\"Annualized Volatility\", value=f\"{backtester.annualized_vol:.2%}\")\n",
        "            if not pd.isna(backtester.sharpe_ratio):\n",
        "                st.metric(label=\"Sharpe Ratio\", value=f\"{backtester.sharpe_ratio:.2f}\")\n",
        "            # The warning is triggered if any of these are NaN. This is the intended behavior.\n",
        "            # if any(pd.isna([backtester.total_return, backtester.annualized_return, backtester.annualized_vol, backtester.sharpe_ratio])):\n",
        "            #      st.warning(\"Could not calculate all portfolio metrics.\")\n",
        "\n",
        "\n",
        "        # --- Benchmark Calculations ---\n",
        "        with col2:\n",
        "            st.subheader(\"S&P 500 (Benchmark)\")\n",
        "            # Check if benchmark data is valid before trying to calculate\n",
        "            # Use .empty to check if the DataFrame/Series is empty\n",
        "            if benchmark_returns is not None and not benchmark_returns.empty and not benchmark_returns.isnull().values.all() and benchmark_cum_returns is not None and not benchmark_cum_returns.empty and len(benchmark_cum_returns) > 1:\n",
        "                try:\n",
        "                    # Use .item() to ensure we have a single Python number\n",
        "                    bench_total_return = (benchmark_cum_returns.iloc[-1] - 1).item()\n",
        "                    # Calculate benchmark duration based on its own data length\n",
        "                    bench_duration_trading_days = len(benchmark_returns)\n",
        "                    bench_annualization_factor = 252 / bench_duration_trading_days if bench_duration_trading_days > 0 else 0\n",
        "\n",
        "                    if bench_annualization_factor > 0:\n",
        "                         bench_annualized_return = (1 + bench_total_return)**(bench_annualization_factor) - 1\n",
        "                         bench_annualized_vol = benchmark_returns.std().item() * np.sqrt(252)\n",
        "\n",
        "                         # Safely calculate Sharpe Ratio for the benchmark\n",
        "                         bench_sharpe_ratio = bench_annualized_return / bench_annualized_vol if bench_annualized_vol > 0 else 0.0\n",
        "\n",
        "                         st.metric(label=\"Total Return\", value=f\"{bench_total_return:.2%}\")\n",
        "                         st.metric(label=\"Annualized Return\", value=f\"{bench_annualized_return:.2%}\")\n",
        "                         st.metric(label=\"Annualized Volatility\", value=f\"{bench_annualized_vol:.2%}\")\n",
        "                         st.metric(label=\"Sharpe Ratio\", value=f\"{bench_sharpe_ratio:.2f}\")\n",
        "                    else:\n",
        "                         st.warning(\"Not enough trading days in benchmark data for annualized metrics.\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error calculating benchmark metrics: {e}\")\n",
        "            else:\n",
        "                st.warning(\"Not enough benchmark data to calculate metrics.\")\n",
        "    else:\n",
        "        st.warning(\"No performance metrics to display. Insufficient data from backtest.\")"
      ],
      "metadata": {
        "id": "mcpJ1si7dpHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c33dffc9"
      },
      "source": [
        "## Run streamlit app\n",
        "\n",
        "### Subtask:\n",
        "Start the Streamlit application using `streamlit run app.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19f1f4e8"
      },
      "source": [
        "**Reasoning**:\n",
        "The Streamlit application code has been written to `app.py`. The next step is to start the Streamlit server to run the application.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a411485"
      },
      "source": [
        "# This script will kill the old processes and start a new one.\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Step 1: Kill any running Streamlit process\n",
        "# This is the crucial step you were missing.\n",
        "print(\"Attempting to kill previous Streamlit process...\")\n",
        "!kill $(ps -ef | grep \"streamlit\" | grep -v \"grep\" | awk '{print $2}')\n",
        "print(\"Kill command sent.\")\n",
        "\n",
        "# Step 2: Disconnect all ngrok tunnels and kill the ngrok process\n",
        "print(\"\\nDisconnecting all ngrok tunnels...\")\n",
        "ngrok.kill()\n",
        "\n",
        "# Step 3: Relaunch everything\n",
        "print(\"Setting up new ngrok tunnel...\")\n",
        "ngrok_token = userdata.get('NGROK_API_KEY')\n",
        "if ngrok_token:\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "else:\n",
        "    print(\"WARNING: NGROK_API_KEY not found in Colab Secrets.\")\n",
        "\n",
        "# Open the tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"New Public URL: {public_url}\")\n",
        "\n",
        "# Run the updated app.py in the background\n",
        "print(\"Starting new Streamlit app...\")\n",
        "!streamlit run app.py &>/dev/null&\n",
        "print(\"App is running in the background. Please use the new public URL.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}